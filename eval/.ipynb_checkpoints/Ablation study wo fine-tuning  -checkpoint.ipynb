{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import codecs\n",
    "import io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from torch import nn\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import sentence_splitter\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.insert(0, \"../utils\")\n",
    "from data_loader import DataLoader\n",
    "from data_writer import DataWriter\n",
    "from pre_processor import PreProcessor\n",
    "from error_analysis import ErrorAnalysis\n",
    "from labels import label2id, id2label\n",
    "from feature_eng import GetFeatures\n",
    "\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "# pd.set_option('display.max_rows', -1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data\n",
      "Read 371 files with succes and 0 failed\n",
      "     Done loading train data\n",
      "Loading test data\n",
      "Read 75 files with succes and 0 failed\n",
      "     Done loading test data\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader()\n",
    "preprocessor = PreProcessor()\n",
    "\n",
    "print(\"Loading train data\")\n",
    "train_df = pd.read_csv(\"../datasets/processed_data/train_data/features/train_data_v2.csv\")\n",
    "train_articles = dataloader.read_articles(\"../datasets/train-articles\")\n",
    "train_df[\"bert_encoding_id\"] = list(range(len(train_df)))\n",
    "print(\"     Done loading train data\")\n",
    "\n",
    "print(\"Loading test data\")\n",
    "test_df = pd.read_csv(\"../datasets/processed_data/dev_data/features/dev_data_v2.csv\")\n",
    "test_articles = dataloader.read_articles(\"../datasets/dev-articles\")\n",
    "test_df[\"bert_encoding_id\"] = list(range(len(test_df)))\n",
    "print(\"     Done loading test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb_path = \"../datasets/processed_data/train_data/embeddings/\"\n",
    "bert_hidden_states = torch.load(train_emb_path + \"bert_hidden_states\" + '.pt')\n",
    "\n",
    "dev_emb_path = \"../datasets/processed_data/dev_data/embeddings/\"\n",
    "bert_dev_hidden_states = torch.load(dev_emb_path + \"bert_dev_hidden_states\" + '.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = preprocessor.preb_targets(train_df, \"gold_label_id\")\n",
    "y_train = torch.tensor(y_train).type(torch.FloatTensor)\n",
    "y_true = train_df[\"gold_label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Straitified 10 fold cross validationnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class-weights\n",
    "labels = set(train_df[\"gold_label\"])\n",
    "label_counter = {label: train_df[\"gold_label\"].values.tolist().count(label) for label in labels}\n",
    "max_class = max(label_counter.values())\n",
    "class_w = {label: max_class / value for label, value in label_counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_train_col = ['span_word_length',\n",
    " 'article_one_word_counter',\n",
    " 'article_span_sentence_counter',\n",
    " 'word_resemble_factor',\n",
    " 'word_count_span_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Fold: 2\n",
      "Fold: 3\n",
      "Fold: 4\n",
      "Fold: 5\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "log_weighted_train_sm = np.zeros((len(train_df),14))\n",
    "log_train_sm = np.zeros((len(train_df),14))\n",
    "\n",
    "for fold_idx, (train_index, test_index) in enumerate(skf.split(train_df, y_true)):\n",
    "    print(\"Fold:\", fold_idx + 1)\n",
    "    # data\n",
    "    tmp_X_train = train_df.iloc[train_index]\n",
    "    tmp_X_test = train_df.iloc[test_index]\n",
    "    tmp_y_train = tmp_X_train[\"gold_label\"]\n",
    "    \n",
    "    logreg = LogisticRegression(penalty='l2', solver=\"lbfgs\")\n",
    "    logreg_weighted = LogisticRegression(penalty='l2',class_weight = class_w, solver=\"lbfgs\")\n",
    "    \n",
    "    # Weighted\n",
    "    logreg_weighted.fit(tmp_X_train[log_train_col], tmp_y_train)\n",
    "    log_weighted_train_sm[test_index] = logreg_weighted.predict_proba(tmp_X_test[log_train_col])\n",
    "    # Not weighted\n",
    "    logreg.fit(tmp_X_train[log_train_col], tmp_y_train)\n",
    "    log_train_sm[test_index] = logreg.predict_proba(tmp_X_test[log_train_col])\n",
    "    fold_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Logreg\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "               Appeal_to_Authority       0.10      0.26      0.15       144\n",
      "          Appeal_to_fear-prejudice       0.09      0.02      0.03       294\n",
      "    Bandwagon,Reductio_ad_hitlerum       0.04      0.22      0.07        72\n",
      "           Black-and-White_Fallacy       0.05      0.14      0.08       107\n",
      "         Causal_Oversimplification       0.17      0.16      0.17       209\n",
      "                             Doubt       0.24      0.02      0.04       493\n",
      "         Exaggeration,Minimisation       0.18      0.25      0.21       466\n",
      "                       Flag-Waving       0.00      0.00      0.00       229\n",
      "                   Loaded_Language       0.77      0.16      0.27      2123\n",
      "             Name_Calling,Labeling       0.24      0.33      0.28      1058\n",
      "                        Repetition       0.52      0.58      0.55       621\n",
      "                           Slogans       0.09      0.61      0.15       129\n",
      "       Thought-terminating_Cliches       0.04      0.28      0.07        76\n",
      "Whataboutism,Straw_Men,Red_Herring       0.05      0.06      0.05       108\n",
      "\n",
      "                          accuracy                           0.23      6129\n",
      "                         macro avg       0.18      0.22      0.15      6129\n",
      "                      weighted avg       0.41      0.23      0.23      6129\n",
      "\n",
      "NOT Weighted Logreg\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "               Appeal_to_Authority       0.00      0.00      0.00       144\n",
      "          Appeal_to_fear-prejudice       0.00      0.00      0.00       294\n",
      "    Bandwagon,Reductio_ad_hitlerum       0.00      0.00      0.00        72\n",
      "           Black-and-White_Fallacy       0.00      0.00      0.00       107\n",
      "         Causal_Oversimplification       0.00      0.00      0.00       209\n",
      "                             Doubt       0.30      0.58      0.40       493\n",
      "         Exaggeration,Minimisation       0.26      0.01      0.02       466\n",
      "                       Flag-Waving       0.00      0.00      0.00       229\n",
      "                   Loaded_Language       0.42      0.96      0.58      2123\n",
      "             Name_Calling,Labeling       0.00      0.00      0.00      1058\n",
      "                        Repetition       0.75      0.30      0.43       621\n",
      "                           Slogans       0.00      0.00      0.00       129\n",
      "       Thought-terminating_Cliches       0.00      0.00      0.00        76\n",
      "Whataboutism,Straw_Men,Red_Herring       0.00      0.00      0.00       108\n",
      "\n",
      "                          accuracy                           0.41      6129\n",
      "                         macro avg       0.12      0.13      0.10      6129\n",
      "                      weighted avg       0.26      0.41      0.28      6129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Weighted Logreg\")\n",
    "\n",
    "print(classification_report(y_true, [id2label[x] for x in np.argmax(log_weighted_train_sm, 1)]))\n",
    "\n",
    "print(\"NOT Weighted Logreg\")\n",
    "print(classification_report(y_true, [id2label[x] for x in np.argmax(log_train_sm, 1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abliation study functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score \n",
    "\n",
    "class ModelFit:\n",
    "    def fit(self, X_train, y_train, X_dev=-1, y_dev=-1, hidden_1=100, hidden_2=100, learning_rate=1e-4, dev_size=0.1, seed=7, verbose=False):\n",
    "        input_dim = X_train.shape[1]\n",
    "        output_dim = 14\n",
    "        if type(X_dev) == int:\n",
    "            split_idx = int(len(X_train) * (1-dev_size))\n",
    "            np.random.seed(seed)\n",
    "            randperm = np.random.permutation(len(X_train))\n",
    "            X_dev = X_train[randperm][split_idx:]\n",
    "            X_train = X_train[randperm][:split_idx]\n",
    "            dev_onehot_labels = y_train[randperm][split_idx:]\n",
    "            train_onehot_labels = y_train[randperm][:split_idx]\n",
    "        else:\n",
    "            dev_onehot_labels = y_dev\n",
    "            train_onehot_labels = y_train\n",
    "\n",
    "        self.nnmodel = nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, hidden_1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_1, hidden_2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_2, output_dim),\n",
    "        )\n",
    "\n",
    "        loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.nnmodel.parameters(), lr=learning_rate)\n",
    "\n",
    "        train_losses = []\n",
    "        dev_losses = []\n",
    "        old_dev_loss = np.infty\n",
    "        for t in range(5000):\n",
    "\n",
    "            y_pred = self.nnmodel(X_train)\n",
    "\n",
    "            train_loss = loss_fn(y_pred, train_onehot_labels)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            new_dev_loss =  loss_fn(self.nnmodel(X_dev), dev_onehot_labels).item()\n",
    "            dev_losses.append(new_dev_loss)\n",
    "            if t%10 == 0:\n",
    "                if verbose:\n",
    "                    print(t, new_dev_loss)\n",
    "                if new_dev_loss < old_dev_loss:\n",
    "                    old_dev_loss = new_dev_loss\n",
    "                    continue\n",
    "                break\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        return self.nnmodel\n",
    "\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_pred = self.nnmodel(X_test)\n",
    "        return y_pred\n",
    "    \n",
    "    def get_label(self, y_pred):\n",
    "        y_pred = y_pred.max(dim = 1)[1]\n",
    "        y_pred = np.array([id2label[x] for x in y_pred.tolist()])\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate model features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_feature_combination(train_cols, train_df, y_true, y_train, w_features=True, w_bert=True, w_log=True, weighted_log=True): \n",
    "    # initialize skf\n",
    "    skf = StratifiedKFold(n_splits = 10, shuffle = True, random_state=1)\n",
    "    # Result metric\n",
    "    logits = np.zeros((len(train_df),14))\n",
    "    \n",
    "    with tqdm(total=10) as pbar:\n",
    "        for fold_idx, (train_index, test_index) in enumerate(skf.split(train_df, y_true)):     \n",
    "            \n",
    "            # With features\n",
    "            if w_features:\n",
    "                \n",
    "                # With logistic regression and features\n",
    "                if w_log:\n",
    "                    \n",
    "                    # With Weighted logreg softmax\n",
    "                    if weighted_log:\n",
    "                        tmp_X_train = log_weighted_train_sm[train_index]\n",
    "                        tmp_X_test = log_weighted_train_sm[test_index]\n",
    "                    # Not weighted logreg\n",
    "                    else:\n",
    "                        tmp_X_train = log_train_sm[train_index]\n",
    "                        tmp_X_test = log_train_sm[test_index]\n",
    "\n",
    "                    # Concat logreg sm with features:\n",
    "                    tmp_X_train = np.concatenate((tmp_X_train, train_df.iloc[train_index][train_cols].to_numpy()), 1)\n",
    "                    tmp_X_test = np.concatenate((tmp_X_test,train_df.iloc[test_index][train_cols].to_numpy()), 1)\n",
    "                \n",
    "                # without logistic regression and but with features\n",
    "                else:\n",
    "                    tmp_X_train = train_df.iloc[train_index][train_cols].to_numpy()\n",
    "                    tmp_X_test = train_df.iloc[test_index][train_cols].to_numpy()\n",
    "\n",
    "                # with features and BERT and logreg if w_logreg\n",
    "                if w_bert:\n",
    "                    hidden_state_train_index = train_df[\"bert_encoding_id\"].iloc[train_index].values\n",
    "                    hidden_state_test_index = train_df[\"bert_encoding_id\"].iloc[test_index].values\n",
    "\n",
    "                    tmp_X_train = torch.cat((bert_hidden_states[hidden_state_train_index], torch.FloatTensor(tmp_X_train)), 1)\n",
    "                    tmp_X_test = torch.cat((bert_hidden_states[hidden_state_test_index], torch.FloatTensor(tmp_X_test)), 1)\n",
    "                # without bert but with feature and logreg if w_logreg\n",
    "                else:\n",
    "                    tmp_X_train = torch.FloatTensor(tmp_X_train)\n",
    "                    tmp_X_test = torch.FloatTensor(tmp_X_test)\n",
    "                    \n",
    "            # Without features\n",
    "            else:\n",
    "                # With logistic regression and without features\n",
    "                if w_log:\n",
    "                    # Weighted or non weighted logreg softmax\n",
    "                    if weighted_log:\n",
    "                        tmp_X_train = log_weighted_train_sm[train_index]\n",
    "                        tmp_X_test = log_weighted_train_sm[test_index]\n",
    "                    else:\n",
    "                        tmp_X_train = log_train_sm[train_index]\n",
    "                        tmp_X_test = log_train_sm[test_index]\n",
    "                    # wo features, but with bert and logreg\n",
    "                    if w_bert:\n",
    "                        hidden_state_train_index = train_df[\"bert_encoding_id\"].iloc[train_index].values\n",
    "                        hidden_state_test_index = train_df[\"bert_encoding_id\"].iloc[test_index].values\n",
    "\n",
    "                        tmp_X_train = torch.cat((bert_hidden_states[hidden_state_train_index], torch.FloatTensor(tmp_X_train)), 1)\n",
    "                        tmp_X_test = torch.cat((bert_hidden_states[hidden_state_test_index], torch.FloatTensor(tmp_X_test)), 1)\n",
    "\n",
    "                # Else without logistic regression and features\n",
    "                # Same as only bert\n",
    "                else:\n",
    "                    hidden_state_train_index = train_df[\"bert_encoding_id\"].iloc[train_index].values\n",
    "                    hidden_state_test_index = train_df[\"bert_encoding_id\"].iloc[test_index].values\n",
    "\n",
    "                    tmp_X_train = bert_hidden_states[hidden_state_train_index]\n",
    "                    tmp_X_test = bert_hidden_states[hidden_state_test_index]\n",
    "\n",
    "            # Train model\n",
    "            model = ModelFit()\n",
    "            model.fit(tmp_X_train, y_train[train_index])\n",
    "\n",
    "            preds = model.predict(tmp_X_test)\n",
    "            logits[test_index] = np.array(preds.tolist())\n",
    "            \n",
    "            pbar.update(1)\n",
    "    # print(classification_report(y_true, [id2label[x] for x in np.argmax(logits, 1)]))\n",
    "    return [id2label[x] for x in np.argmax(logits, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:00<00:00, 12.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "               Appeal_to_Authority       0.45      0.16      0.24       144\n",
      "          Appeal_to_fear-prejudice       0.43      0.46      0.44       294\n",
      "    Bandwagon,Reductio_ad_hitlerum       0.57      0.11      0.19        72\n",
      "           Black-and-White_Fallacy       0.32      0.07      0.11       107\n",
      "         Causal_Oversimplification       0.43      0.33      0.37       209\n",
      "                             Doubt       0.56      0.76      0.64       493\n",
      "         Exaggeration,Minimisation       0.55      0.44      0.49       466\n",
      "                       Flag-Waving       0.59      0.59      0.59       229\n",
      "                   Loaded_Language       0.71      0.85      0.77      2123\n",
      "             Name_Calling,Labeling       0.72      0.80      0.76      1058\n",
      "                        Repetition       0.65      0.53      0.58       621\n",
      "                           Slogans       0.68      0.28      0.40       129\n",
      "       Thought-terminating_Cliches       0.33      0.08      0.13        76\n",
      "Whataboutism,Straw_Men,Red_Herring       0.50      0.01      0.02       108\n",
      "\n",
      "                          accuracy                           0.65      6129\n",
      "                         macro avg       0.53      0.39      0.41      6129\n",
      "                      weighted avg       0.63      0.65      0.62      6129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test functionn with bert only\n",
    "preds = validate_feature_combination(log_train_col, train_df, y_true, y_train, w_features=False, w_bert=True, w_log=False, weighted_log=False)\n",
    "print(classification_report(y_true, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = ['span_word_length',\n",
    " 'article_one_word_counter',\n",
    " 'article_span_sentence_counter',\n",
    " 'word_resemble_factor',\n",
    " 'word_count_span_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = {\"Bert Only\":{\"train_cols\":train_cols, \n",
    "                             \"train_df\":train_df, \n",
    "                             \"y_true\":y_true, \n",
    "                             \"y_train\":y_train, \n",
    "                             \"w_features\":False, \n",
    "                             \"w_bert\":True, \n",
    "                             \"w_log\":False, \n",
    "                             \"weighted_log\":False\n",
    "                            }, \n",
    "                \"Bert and all HC\":{\"train_cols\":train_cols, \n",
    "                                 \"train_df\":train_df, \n",
    "                                 \"y_true\":y_true, \n",
    "                                 \"y_train\":y_train, \n",
    "                                 \"w_features\":True, \n",
    "                                 \"w_bert\":True, \n",
    "                                 \"w_log\":False, \n",
    "                                 \"weighted_log\":False\n",
    "                                },\n",
    "                \"Bert and wLogreg\":{\"train_cols\":train_cols, \n",
    "                                 \"train_df\":train_df, \n",
    "                                 \"y_true\":y_true, \n",
    "                                 \"y_train\":y_train, \n",
    "                                 \"w_features\":False, \n",
    "                                 \"w_bert\":True, \n",
    "                                 \"w_log\":True, \n",
    "                                 \"weighted_log\":True\n",
    "                                },\n",
    "                \"Bert and logreg\":{\"train_cols\":train_cols, \n",
    "                                 \"train_df\":train_df, \n",
    "                                 \"y_true\":y_true, \n",
    "                                 \"y_train\":y_train, \n",
    "                                 \"w_features\":False, \n",
    "                                 \"w_bert\":True, \n",
    "                                 \"w_log\":True, \n",
    "                                 \"weighted_log\":False\n",
    "                                },\n",
    "                \"logreg and all HC\":{\"train_cols\":train_cols, \n",
    "                                 \"train_df\":train_df, \n",
    "                                 \"y_true\":y_true, \n",
    "                                 \"y_train\":y_train, \n",
    "                                 \"w_features\":True, \n",
    "                                 \"w_bert\":False, \n",
    "                                 \"w_log\":True, \n",
    "                                 \"weighted_log\":False\n",
    "                                },\n",
    "                \"wlogreg and all HC\":{\"train_cols\":train_cols, \n",
    "                                 \"train_df\":train_df, \n",
    "                                 \"y_true\":y_true, \n",
    "                                 \"y_train\":y_train, \n",
    "                                 \"w_features\":True, \n",
    "                                 \"w_bert\":False, \n",
    "                                 \"w_log\":True, \n",
    "                                 \"weighted_log\":True\n",
    "                                },\n",
    "                \"Bert, wLogreg and all HC\":{\"train_cols\":train_cols, \n",
    "                                         \"train_df\":train_df, \n",
    "                                         \"y_true\":y_true, \n",
    "                                         \"y_train\":y_train, \n",
    "                                         \"w_features\":True, \n",
    "                                         \"w_bert\":True, \n",
    "                                         \"w_log\":True, \n",
    "                                         \"weighted_log\":True\n",
    "                                        }, \n",
    "                \"Bert, Logreg and all HC\":{\"train_cols\":train_cols, \n",
    "                                         \"train_df\":train_df, \n",
    "                                         \"y_true\":y_true, \n",
    "                                         \"y_train\":y_train, \n",
    "                                         \"w_features\":True, \n",
    "                                         \"w_bert\":True, \n",
    "                                         \"w_log\":True, \n",
    "                                         \"weighted_log\":False\n",
    "                                          }\n",
    "               }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Bert Only\n",
      "Model #1 out of 8 models\n",
      "______________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:09<00:00, 12.92s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro f1 = 0.6462718224832762\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "               Appeal_to_Authority       0.36      0.15      0.21       144\n",
      "          Appeal_to_fear-prejudice       0.43      0.47      0.45       294\n",
      "    Bandwagon,Reductio_ad_hitlerum       0.60      0.08      0.15        72\n",
      "           Black-and-White_Fallacy       0.37      0.07      0.11       107\n",
      "         Causal_Oversimplification       0.46      0.34      0.39       209\n",
      "                             Doubt       0.56      0.76      0.64       493\n",
      "         Exaggeration,Minimisation       0.55      0.43      0.49       466\n",
      "                       Flag-Waving       0.60      0.58      0.59       229\n",
      "                   Loaded_Language       0.70      0.85      0.77      2123\n",
      "             Name_Calling,Labeling       0.72      0.79      0.75      1058\n",
      "                        Repetition       0.65      0.52      0.58       621\n",
      "                           Slogans       0.65      0.26      0.37       129\n",
      "       Thought-terminating_Cliches       0.38      0.13      0.20        76\n",
      "Whataboutism,Straw_Men,Red_Herring       0.67      0.02      0.04       108\n",
      "\n",
      "                          accuracy                           0.65      6129\n",
      "                         macro avg       0.55      0.39      0.41      6129\n",
      "                      weighted avg       0.63      0.65      0.62      6129\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "Bert and all HC\n",
      "Model #2 out of 8 models\n",
      "______________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:13<00:00, 13.85s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro f1 = 0.6537771251427639\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "               Appeal_to_Authority       0.43      0.18      0.25       144\n",
      "          Appeal_to_fear-prejudice       0.45      0.47      0.46       294\n",
      "    Bandwagon,Reductio_ad_hitlerum       0.56      0.12      0.20        72\n",
      "           Black-and-White_Fallacy       0.31      0.05      0.08       107\n",
      "         Causal_Oversimplification       0.44      0.32      0.37       209\n",
      "                             Doubt       0.56      0.76      0.65       493\n",
      "         Exaggeration,Minimisation       0.55      0.45      0.50       466\n",
      "                       Flag-Waving       0.58      0.57      0.57       229\n",
      "                   Loaded_Language       0.71      0.85      0.78      2123\n",
      "             Name_Calling,Labeling       0.72      0.79      0.75      1058\n",
      "                        Repetition       0.68      0.57      0.62       621\n",
      "                           Slogans       0.66      0.29      0.41       129\n",
      "       Thought-terminating_Cliches       0.44      0.14      0.22        76\n",
      "Whataboutism,Straw_Men,Red_Herring       0.75      0.03      0.05       108\n",
      "\n",
      "                          accuracy                           0.65      6129\n",
      "                         macro avg       0.56      0.40      0.42      6129\n",
      "                      weighted avg       0.64      0.65      0.63      6129\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "Bert and wLogreg\n",
      "Model #3 out of 8 models\n",
      "______________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:14<00:00, 13.20s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro f1 = 0.6495349975526187\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "               Appeal_to_Authority       0.49      0.18      0.26       144\n",
      "          Appeal_to_fear-prejudice       0.45      0.46      0.46       294\n",
      "    Bandwagon,Reductio_ad_hitlerum       0.64      0.12      0.21        72\n",
      "           Black-and-White_Fallacy       0.58      0.10      0.17       107\n",
      "         Causal_Oversimplification       0.43      0.33      0.38       209\n",
      "                             Doubt       0.56      0.75      0.64       493\n",
      "         Exaggeration,Minimisation       0.54      0.44      0.49       466\n",
      "                       Flag-Waving       0.58      0.59      0.59       229\n",
      "                   Loaded_Language       0.71      0.85      0.77      2123\n",
      "             Name_Calling,Labeling       0.72      0.79      0.76      1058\n",
      "                        Repetition       0.65      0.54      0.59       621\n",
      "                           Slogans       0.56      0.19      0.28       129\n",
      "       Thought-terminating_Cliches       0.36      0.11      0.16        76\n",
      "Whataboutism,Straw_Men,Red_Herring       0.25      0.01      0.02       108\n",
      "\n",
      "                          accuracy                           0.65      6129\n",
      "                         macro avg       0.54      0.39      0.41      6129\n",
      "                      weighted avg       0.63      0.65      0.62      6129\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "Bert and logreg\n",
      "Model #4 out of 8 models\n",
      "______________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:17<00:00, 14.66s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro f1 = 0.6514929025942242\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "               Appeal_to_Authority       0.43      0.16      0.23       144\n",
      "          Appeal_to_fear-prejudice       0.45      0.50      0.47       294\n",
      "    Bandwagon,Reductio_ad_hitlerum       0.60      0.12      0.21        72\n",
      "           Black-and-White_Fallacy       0.44      0.11      0.18       107\n",
      "         Causal_Oversimplification       0.43      0.35      0.39       209\n",
      "                             Doubt       0.55      0.75      0.64       493\n",
      "         Exaggeration,Minimisation       0.55      0.45      0.49       466\n",
      "                       Flag-Waving       0.62      0.59      0.60       229\n",
      "                   Loaded_Language       0.71      0.85      0.77      2123\n",
      "             Name_Calling,Labeling       0.73      0.80      0.76      1058\n",
      "                        Repetition       0.66      0.52      0.58       621\n",
      "                           Slogans       0.61      0.24      0.34       129\n",
      "       Thought-terminating_Cliches       0.32      0.09      0.14        76\n",
      "Whataboutism,Straw_Men,Red_Herring       0.00      0.00      0.00       108\n",
      "\n",
      "                          accuracy                           0.65      6129\n",
      "                         macro avg       0.51      0.40      0.42      6129\n",
      "                      weighted avg       0.63      0.65      0.63      6129\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "logreg and all HC\n",
      "Model #5 out of 8 models\n",
      "______________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:39<00:00,  9.09s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro f1 = 0.4454233969652472\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "               Appeal_to_Authority       0.00      0.00      0.00       144\n",
      "          Appeal_to_fear-prejudice       0.00      0.00      0.00       294\n",
      "    Bandwagon,Reductio_ad_hitlerum       0.00      0.00      0.00        72\n",
      "           Black-and-White_Fallacy       0.00      0.00      0.00       107\n",
      "         Causal_Oversimplification       0.00      0.00      0.00       209\n",
      "                             Doubt       0.27      0.70      0.39       493\n",
      "         Exaggeration,Minimisation       0.00      0.00      0.00       466\n",
      "                       Flag-Waving       0.00      0.00      0.00       229\n",
      "                   Loaded_Language       0.51      0.82      0.63      2123\n",
      "             Name_Calling,Labeling       0.35      0.33      0.34      1058\n",
      "                        Repetition       0.65      0.48      0.55       621\n",
      "                           Slogans       0.00      0.00      0.00       129\n",
      "       Thought-terminating_Cliches       0.00      0.00      0.00        76\n",
      "Whataboutism,Straw_Men,Red_Herring       0.00      0.00      0.00       108\n",
      "\n",
      "                          accuracy                           0.45      6129\n",
      "                         macro avg       0.13      0.17      0.14      6129\n",
      "                      weighted avg       0.33      0.45      0.36      6129\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "wlogreg and all HC\n",
      "Model #6 out of 8 models\n",
      "______________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:35<00:00,  8.36s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro f1 = 0.4434654919236417\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "               Appeal_to_Authority       0.00      0.00      0.00       144\n",
      "          Appeal_to_fear-prejudice       0.00      0.00      0.00       294\n",
      "    Bandwagon,Reductio_ad_hitlerum       0.00      0.00      0.00        72\n",
      "           Black-and-White_Fallacy       0.00      0.00      0.00       107\n",
      "         Causal_Oversimplification       0.00      0.00      0.00       209\n",
      "                             Doubt       0.27      0.70      0.39       493\n",
      "         Exaggeration,Minimisation       0.00      0.00      0.00       466\n",
      "                       Flag-Waving       0.00      0.00      0.00       229\n",
      "                   Loaded_Language       0.52      0.81      0.63      2123\n",
      "             Name_Calling,Labeling       0.34      0.34      0.34      1058\n",
      "                        Repetition       0.65      0.47      0.54       621\n",
      "                           Slogans       0.00      0.00      0.00       129\n",
      "       Thought-terminating_Cliches       0.00      0.00      0.00        76\n",
      "Whataboutism,Straw_Men,Red_Herring       0.00      0.00      0.00       108\n",
      "\n",
      "                          accuracy                           0.44      6129\n",
      "                         macro avg       0.13      0.17      0.14      6129\n",
      "                      weighted avg       0.33      0.44      0.36      6129\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "Bert, wLogreg and all HC\n",
      "Model #7 out of 8 models\n",
      "______________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:14<00:00, 13.66s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro f1 = 0.6482297275248817\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "               Appeal_to_Authority       0.53      0.20      0.29       144\n",
      "          Appeal_to_fear-prejudice       0.44      0.50      0.46       294\n",
      "    Bandwagon,Reductio_ad_hitlerum       0.44      0.10      0.16        72\n",
      "           Black-and-White_Fallacy       0.38      0.06      0.10       107\n",
      "         Causal_Oversimplification       0.41      0.27      0.33       209\n",
      "                             Doubt       0.56      0.76      0.64       493\n",
      "         Exaggeration,Minimisation       0.53      0.42      0.47       466\n",
      "                       Flag-Waving       0.60      0.57      0.58       229\n",
      "                   Loaded_Language       0.70      0.85      0.77      2123\n",
      "             Name_Calling,Labeling       0.72      0.79      0.75      1058\n",
      "                        Repetition       0.69      0.55      0.61       621\n",
      "                           Slogans       0.65      0.24      0.35       129\n",
      "       Thought-terminating_Cliches       0.42      0.13      0.20        76\n",
      "Whataboutism,Straw_Men,Red_Herring       0.25      0.01      0.02       108\n",
      "\n",
      "                          accuracy                           0.65      6129\n",
      "                         macro avg       0.52      0.39      0.41      6129\n",
      "                      weighted avg       0.63      0.65      0.62      6129\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "Bert, Logreg and all HC\n",
      "Model #8 out of 8 models\n",
      "______________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:18<00:00, 14.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro f1 = 0.6534508076358296\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "               Appeal_to_Authority       0.51      0.25      0.33       144\n",
      "          Appeal_to_fear-prejudice       0.45      0.48      0.47       294\n",
      "    Bandwagon,Reductio_ad_hitlerum       0.77      0.14      0.24        72\n",
      "           Black-and-White_Fallacy       0.38      0.07      0.12       107\n",
      "         Causal_Oversimplification       0.45      0.33      0.38       209\n",
      "                             Doubt       0.56      0.75      0.64       493\n",
      "         Exaggeration,Minimisation       0.56      0.45      0.50       466\n",
      "                       Flag-Waving       0.59      0.59      0.59       229\n",
      "                   Loaded_Language       0.71      0.85      0.77      2123\n",
      "             Name_Calling,Labeling       0.72      0.79      0.75      1058\n",
      "                        Repetition       0.68      0.56      0.61       621\n",
      "                           Slogans       0.66      0.22      0.34       129\n",
      "       Thought-terminating_Cliches       0.35      0.09      0.15        76\n",
      "Whataboutism,Straw_Men,Red_Herring       0.67      0.02      0.04       108\n",
      "\n",
      "                          accuracy                           0.65      6129\n",
      "                         macro avg       0.57      0.40      0.42      6129\n",
      "                      weighted avg       0.64      0.65      0.63      6129\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = dict()\n",
    "model_num = 1\n",
    "for name, params in combinations.items():\n",
    "    print(\"\\n{}\\n\".format(\"=\"*60), name, \"\\nModel #{} out of {} models\\n{}\\n\".format(model_num, len(combinations),\"_\"*30), sep=\"\")\n",
    "    model_num += 1\n",
    "    preds = validate_feature_combination(**params)\n",
    "    f1 = f1_score(y_true, preds, average=\"micro\")\n",
    "    results[name] = (f1, preds)\n",
    "    print(\"Micro f1 = {}\".format(f1))\n",
    "    print(classification_report(y_true, preds))\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "HC_only = {\"HC only\": {\"train_cols\":train_cols, \n",
    "          \"train_df\":train_df, \n",
    "          \"y_true\":y_true, \n",
    "          \"y_train\":y_train, \n",
    "          \"w_features\":True, \n",
    "          \"w_bert\":False, \n",
    "          \"w_log\":False, \n",
    "          \"weighted_log\":False}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "HC only\n",
      "Model #1 out of 8 models\n",
      "______________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:30<00:00,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro f1 = 0.4444444444444444\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "               Appeal_to_Authority       0.00      0.00      0.00       144\n",
      "          Appeal_to_fear-prejudice       0.00      0.00      0.00       294\n",
      "    Bandwagon,Reductio_ad_hitlerum       0.00      0.00      0.00        72\n",
      "           Black-and-White_Fallacy       0.00      0.00      0.00       107\n",
      "         Causal_Oversimplification       0.00      0.00      0.00       209\n",
      "                             Doubt       0.27      0.70      0.39       493\n",
      "         Exaggeration,Minimisation       0.00      0.00      0.00       466\n",
      "                       Flag-Waving       0.00      0.00      0.00       229\n",
      "                   Loaded_Language       0.52      0.82      0.63      2123\n",
      "             Name_Calling,Labeling       0.34      0.33      0.34      1058\n",
      "                        Repetition       0.64      0.48      0.55       621\n",
      "                           Slogans       0.00      0.00      0.00       129\n",
      "       Thought-terminating_Cliches       0.00      0.00      0.00        76\n",
      "Whataboutism,Straw_Men,Red_Herring       0.00      0.00      0.00       108\n",
      "\n",
      "                          accuracy                           0.44      6129\n",
      "                         macro avg       0.13      0.17      0.14      6129\n",
      "                      weighted avg       0.32      0.44      0.36      6129\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_num = 1\n",
    "for name, params in HC_only.items():\n",
    "    print(\"\\n{}\\n\".format(\"=\"*60), name, \"\\nModel #{} out of {} models\\n{}\\n\".format(model_num, len(combinations),\"_\"*30), sep=\"\")\n",
    "    model_num += 1\n",
    "    preds = validate_feature_combination(**params)\n",
    "    f1 = f1_score(y_true, preds, average=\"micro\")\n",
    "    results[name] = (f1, preds)\n",
    "    print(\"Micro f1 = {}\".format(f1))\n",
    "    print(classification_report(y_true, preds))\n",
    "    print()\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_overview = [(name, x[0]) for name, x  in  sorted(results.items(), key=lambda x: x[1][0], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bert and all HC', 0.6537771251427639),\n",
       " ('Bert, Logreg and all HC', 0.6534508076358296),\n",
       " ('Bert and logreg', 0.6514929025942242),\n",
       " ('Bert and wLogreg', 0.6495349975526187),\n",
       " ('Bert, wLogreg and all HC', 0.6482297275248817),\n",
       " ('Bert Only', 0.6462718224832762),\n",
       " ('logreg and all HC', 0.4454233969652472),\n",
       " ('HC only', 0.4444444444444444),\n",
       " ('wlogreg and all HC', 0.4434654919236417)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining Bert and all HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = ['span_word_length',\n",
    " 'article_one_word_counter',\n",
    " 'article_span_sentence_counter',\n",
    " 'word_resemble_factor',\n",
    " 'word_count_span_sent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_combinations = {\"wo_\"+ablation_col: [col for col in train_cols if col != ablation_col] for ablation_col in train_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"train_cols\":train_cols, \n",
    "          \"train_df\":train_df, \n",
    "          \"y_true\":y_true, \n",
    "          \"y_train\":y_train, \n",
    "          \"w_features\":True, \n",
    "          \"w_bert\":True, \n",
    "          \"w_log\":True, \n",
    "          \"weighted_log\":False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "wo_span_word_length\n",
      "Feature comp. #1 out of 5 combinations\n",
      "______________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:09<00:00, 13.27s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro f1 = 0.6537771251427639\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "               Appeal_to_Authority       0.45      0.17      0.25       144\n",
      "          Appeal_to_fear-prejudice       0.44      0.47      0.46       294\n",
      "    Bandwagon,Reductio_ad_hitlerum       0.65      0.18      0.28        72\n",
      "           Black-and-White_Fallacy       0.44      0.07      0.13       107\n",
      "         Causal_Oversimplification       0.46      0.35      0.40       209\n",
      "                             Doubt       0.55      0.77      0.64       493\n",
      "         Exaggeration,Minimisation       0.55      0.44      0.49       466\n",
      "                       Flag-Waving       0.59      0.59      0.59       229\n",
      "                   Loaded_Language       0.71      0.85      0.78      2123\n",
      "             Name_Calling,Labeling       0.72      0.79      0.75      1058\n",
      "                        Repetition       0.70      0.55      0.62       621\n",
      "                           Slogans       0.62      0.19      0.30       129\n",
      "       Thought-terminating_Cliches       0.47      0.11      0.17        76\n",
      "Whataboutism,Straw_Men,Red_Herring       0.75      0.03      0.05       108\n",
      "\n",
      "                          accuracy                           0.65      6129\n",
      "                         macro avg       0.58      0.40      0.42      6129\n",
      "                      weighted avg       0.64      0.65      0.63      6129\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "wo_article_one_word_counter\n",
      "Feature comp. #2 out of 5 combinations\n",
      "______________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:13<00:00, 14.44s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro f1 = 0.6510034263338228\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "               Appeal_to_Authority       0.48      0.21      0.29       144\n",
      "          Appeal_to_fear-prejudice       0.45      0.48      0.46       294\n",
      "    Bandwagon,Reductio_ad_hitlerum       0.62      0.11      0.19        72\n",
      "           Black-and-White_Fallacy       0.47      0.07      0.13       107\n",
      "         Causal_Oversimplification       0.41      0.32      0.36       209\n",
      "                             Doubt       0.56      0.77      0.65       493\n",
      "         Exaggeration,Minimisation       0.57      0.45      0.51       466\n",
      "                       Flag-Waving       0.57      0.57      0.57       229\n",
      "                   Loaded_Language       0.71      0.84      0.77      2123\n",
      "             Name_Calling,Labeling       0.72      0.80      0.76      1058\n",
      "                        Repetition       0.64      0.54      0.58       621\n",
      "                           Slogans       0.62      0.29      0.40       129\n",
      "       Thought-terminating_Cliches       0.42      0.07      0.11        76\n",
      "Whataboutism,Straw_Men,Red_Herring       0.75      0.03      0.05       108\n",
      "\n",
      "                          accuracy                           0.65      6129\n",
      "                         macro avg       0.57      0.40      0.42      6129\n",
      "                      weighted avg       0.64      0.65      0.63      6129\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "wo_article_span_sentence_counter\n",
      "Feature comp. #3 out of 5 combinations\n",
      "______________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:15<00:00, 13.48s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro f1 = 0.6527981726219612\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "               Appeal_to_Authority       0.57      0.19      0.28       144\n",
      "          Appeal_to_fear-prejudice       0.45      0.48      0.46       294\n",
      "    Bandwagon,Reductio_ad_hitlerum       0.43      0.08      0.14        72\n",
      "           Black-and-White_Fallacy       0.37      0.07      0.11       107\n",
      "         Causal_Oversimplification       0.43      0.32      0.37       209\n",
      "                             Doubt       0.55      0.77      0.64       493\n",
      "         Exaggeration,Minimisation       0.54      0.43      0.48       466\n",
      "                       Flag-Waving       0.59      0.58      0.59       229\n",
      "                   Loaded_Language       0.71      0.86      0.77      2123\n",
      "             Name_Calling,Labeling       0.72      0.79      0.75      1058\n",
      "                        Repetition       0.70      0.54      0.61       621\n",
      "                           Slogans       0.60      0.30      0.40       129\n",
      "       Thought-terminating_Cliches       0.44      0.09      0.15        76\n",
      "Whataboutism,Straw_Men,Red_Herring       0.50      0.02      0.04       108\n",
      "\n",
      "                          accuracy                           0.65      6129\n",
      "                         macro avg       0.54      0.39      0.41      6129\n",
      "                      weighted avg       0.64      0.65      0.63      6129\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "wo_word_resemble_factor\n",
      "Feature comp. #4 out of 5 combinations\n",
      "______________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:10<00:00, 12.67s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro f1 = 0.6519823788546255\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "               Appeal_to_Authority       0.48      0.19      0.28       144\n",
      "          Appeal_to_fear-prejudice       0.44      0.47      0.45       294\n",
      "    Bandwagon,Reductio_ad_hitlerum       0.62      0.11      0.19        72\n",
      "           Black-and-White_Fallacy       0.43      0.08      0.14       107\n",
      "         Causal_Oversimplification       0.43      0.33      0.37       209\n",
      "                             Doubt       0.56      0.76      0.64       493\n",
      "         Exaggeration,Minimisation       0.56      0.44      0.49       466\n",
      "                       Flag-Waving       0.60      0.57      0.58       229\n",
      "                   Loaded_Language       0.70      0.86      0.77      2123\n",
      "             Name_Calling,Labeling       0.72      0.80      0.76      1058\n",
      "                        Repetition       0.69      0.54      0.61       621\n",
      "                           Slogans       0.56      0.23      0.33       129\n",
      "       Thought-terminating_Cliches       0.36      0.07      0.11        76\n",
      "Whataboutism,Straw_Men,Red_Herring       1.00      0.02      0.04       108\n",
      "\n",
      "                          accuracy                           0.65      6129\n",
      "                         macro avg       0.58      0.39      0.41      6129\n",
      "                      weighted avg       0.64      0.65      0.63      6129\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "wo_word_count_span_sent\n",
      "Feature comp. #5 out of 5 combinations\n",
      "______________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:12<00:00, 13.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro f1 = 0.6524718551150269\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "               Appeal_to_Authority       0.57      0.24      0.33       144\n",
      "          Appeal_to_fear-prejudice       0.44      0.47      0.45       294\n",
      "    Bandwagon,Reductio_ad_hitlerum       0.73      0.11      0.19        72\n",
      "           Black-and-White_Fallacy       0.39      0.07      0.11       107\n",
      "         Causal_Oversimplification       0.43      0.34      0.38       209\n",
      "                             Doubt       0.56      0.77      0.65       493\n",
      "         Exaggeration,Minimisation       0.54      0.43      0.48       466\n",
      "                       Flag-Waving       0.58      0.56      0.57       229\n",
      "                   Loaded_Language       0.71      0.85      0.77      2123\n",
      "             Name_Calling,Labeling       0.72      0.79      0.76      1058\n",
      "                        Repetition       0.70      0.55      0.62       621\n",
      "                           Slogans       0.58      0.25      0.35       129\n",
      "       Thought-terminating_Cliches       0.43      0.08      0.13        76\n",
      "Whataboutism,Straw_Men,Red_Herring       0.50      0.01      0.02       108\n",
      "\n",
      "                          accuracy                           0.65      6129\n",
      "                         macro avg       0.56      0.39      0.42      6129\n",
      "                      weighted avg       0.64      0.65      0.63      6129\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_v2 = dict()\n",
    "combination_num = 1\n",
    "for name, tmp_features in feature_combinations.items():\n",
    "    print(\"\\n{}\\n\".format(\"=\"*60), name, \"\\nFeature comp. #{} out of {} combinations\\n{}\\n\".format(combination_num, len(feature_combinations),\"_\"*30), sep=\"\")\n",
    "    combination_num += 1\n",
    "    params[\"train_cols\"] = tmp_features\n",
    "    preds = validate_feature_combination(**params)\n",
    "    f1 = f1_score(y_true, preds, average=\"micro\")\n",
    "    results_v2[name] = (f1, preds)\n",
    "    print(\"Micro f1 = {}\".format(f1))\n",
    "    print(classification_report(y_true, preds))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_v2_overview = [(name, res[0]) for name, res in sorted(results_v2.items(), key=lambda x : x[1][0], reverse = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wo_span_word_length', 0.6537771251427639),\n",
       " ('wo_article_span_sentence_counter', 0.6527981726219612),\n",
       " ('wo_word_count_span_sent', 0.6524718551150269),\n",
       " ('wo_word_resemble_factor', 0.6519823788546255),\n",
       " ('wo_article_one_word_counter', 0.6510034263338228)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_v2_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_features_combinations = [[\"span_word_length\", \"word_resemble_factor\"], [\"span_word_length\", \"word_resemble_factor\", \"word_count_span_sent\"], [\"span_word_length\", \"word_resemble_factor\", \"word_count_span_sent\", \"article_one_word_counter\"]]\n",
    "wo_worst_features = {\"wo_comp_\" + str(i) : [col for col in train_cols if col not in abliat_cols] for i, abliat_cols in enumerate(worst_features_combinations)}\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['span_word_length', 'word_resemble_factor'],\n",
       " ['span_word_length', 'word_resemble_factor', 'word_count_span_sent'],\n",
       " ['span_word_length',\n",
       "  'word_resemble_factor',\n",
       "  'word_count_span_sent',\n",
       "  'article_one_word_counter']]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_features_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wo_comp_0': ['article_one_word_counter',\n",
       "  'article_span_sentence_counter',\n",
       "  'word_count_span_sent'],\n",
       " 'wo_comp_1': ['article_one_word_counter', 'article_span_sentence_counter'],\n",
       " 'wo_comp_2': ['article_span_sentence_counter']}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wo_worst_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "wo_comp_0\n",
      "Feature comp. #1 out of 3 combinations\n",
      "______________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:11<00:00, 13.34s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro f1 = 0.6536139663892968\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "               Appeal_to_Authority       0.50      0.20      0.29       144\n",
      "          Appeal_to_fear-prejudice       0.45      0.48      0.47       294\n",
      "    Bandwagon,Reductio_ad_hitlerum       0.50      0.12      0.20        72\n",
      "           Black-and-White_Fallacy       0.41      0.08      0.14       107\n",
      "         Causal_Oversimplification       0.46      0.33      0.38       209\n",
      "                             Doubt       0.55      0.76      0.64       493\n",
      "         Exaggeration,Minimisation       0.55      0.46      0.50       466\n",
      "                       Flag-Waving       0.60      0.58      0.59       229\n",
      "                   Loaded_Language       0.71      0.85      0.77      2123\n",
      "             Name_Calling,Labeling       0.73      0.79      0.76      1058\n",
      "                        Repetition       0.69      0.56      0.61       621\n",
      "                           Slogans       0.57      0.23      0.33       129\n",
      "       Thought-terminating_Cliches       0.40      0.11      0.17        76\n",
      "Whataboutism,Straw_Men,Red_Herring       0.50      0.02      0.04       108\n",
      "\n",
      "                          accuracy                           0.65      6129\n",
      "                         macro avg       0.54      0.40      0.42      6129\n",
      "                      weighted avg       0.64      0.65      0.63      6129\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "wo_comp_1\n",
      "Feature comp. #2 out of 3 combinations\n",
      "______________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:28<00:00, 15.51s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro f1 = 0.6521455376080927\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "               Appeal_to_Authority       0.40      0.13      0.20       144\n",
      "          Appeal_to_fear-prejudice       0.43      0.45      0.44       294\n",
      "    Bandwagon,Reductio_ad_hitlerum       0.73      0.15      0.25        72\n",
      "           Black-and-White_Fallacy       0.55      0.11      0.19       107\n",
      "         Causal_Oversimplification       0.45      0.33      0.39       209\n",
      "                             Doubt       0.56      0.76      0.64       493\n",
      "         Exaggeration,Minimisation       0.55      0.45      0.49       466\n",
      "                       Flag-Waving       0.59      0.59      0.59       229\n",
      "                   Loaded_Language       0.70      0.85      0.77      2123\n",
      "             Name_Calling,Labeling       0.73      0.79      0.76      1058\n",
      "                        Repetition       0.69      0.56      0.62       621\n",
      "                           Slogans       0.64      0.29      0.40       129\n",
      "       Thought-terminating_Cliches       0.33      0.08      0.13        76\n",
      "Whataboutism,Straw_Men,Red_Herring       0.33      0.02      0.04       108\n",
      "\n",
      "                          accuracy                           0.65      6129\n",
      "                         macro avg       0.55      0.40      0.42      6129\n",
      "                      weighted avg       0.64      0.65      0.63      6129\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "wo_comp_2\n",
      "Feature comp. #3 out of 3 combinations\n",
      "______________________________\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:21<00:00, 14.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro f1 = 0.648556045031816\n",
      "                                    precision    recall  f1-score   support\n",
      "\n",
      "               Appeal_to_Authority       0.49      0.17      0.26       144\n",
      "          Appeal_to_fear-prejudice       0.43      0.47      0.45       294\n",
      "    Bandwagon,Reductio_ad_hitlerum       0.56      0.12      0.20        72\n",
      "           Black-and-White_Fallacy       0.56      0.09      0.16       107\n",
      "         Causal_Oversimplification       0.43      0.35      0.39       209\n",
      "                             Doubt       0.55      0.75      0.64       493\n",
      "         Exaggeration,Minimisation       0.56      0.43      0.48       466\n",
      "                       Flag-Waving       0.56      0.55      0.56       229\n",
      "                   Loaded_Language       0.71      0.85      0.77      2123\n",
      "             Name_Calling,Labeling       0.72      0.80      0.76      1058\n",
      "                        Repetition       0.65      0.54      0.59       621\n",
      "                           Slogans       0.69      0.27      0.39       129\n",
      "       Thought-terminating_Cliches       0.36      0.07      0.11        76\n",
      "Whataboutism,Straw_Men,Red_Herring       0.60      0.03      0.05       108\n",
      "\n",
      "                          accuracy                           0.65      6129\n",
      "                         macro avg       0.56      0.39      0.42      6129\n",
      "                      weighted avg       0.64      0.65      0.62      6129\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_v3 = dict()\n",
    "combination_num = 1\n",
    "for name, tmp_features in wo_worst_features.items():\n",
    "    print(\"\\n{}\\n\".format(\"=\"*60), name, \"\\nFeature comp. #{} out of {} combinations\\n{}\\n\".format(combination_num, len(wo_worst_features),\"_\"*30), sep=\"\")\n",
    "    combination_num += 1\n",
    "    params[\"train_cols\"] = tmp_features\n",
    "    preds = validate_feature_combination(**params)\n",
    "    f1 = f1_score(y_true, preds, average=\"micro\")\n",
    "    results_v3[name] = (f1, preds)\n",
    "    print(\"Micro f1 = {}\".format(f1))\n",
    "    print(classification_report(y_true, preds))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_v3_overview = [(name, res[0]) for name, res in sorted(results_v3.items(), key=lambda x : x[1][0], reverse = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wo_comp_0', 0.6536139663892968),\n",
       " ('wo_comp_1', 0.6521455376080927),\n",
       " ('wo_comp_2', 0.648556045031816)]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_v3_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_X_train = np.concatenate((log_train_sm, train_df[train_cols].to_numpy()), 1)\n",
    "ens_X_train = torch.cat((bert_hidden_states[train_df[\"bert_encoding_id\"].values], torch.FloatTensor(ens_X_train)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_weighted = LogisticRegression(penalty='l2', solver=\"lbfgs\")\n",
    "logreg_weighted.fit(train_df[train_cols], y_true)\n",
    "log_baseline_test = logreg_weighted.predict_proba(test_df[train_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_X_test = np.concatenate((log_baseline_test, test_df[train_cols].to_numpy()), 1)\n",
    "ens_X_test = torch.cat((bert_dev_hidden_states[test_df[\"bert_encoding_id\"].values], torch.FloatTensor(ens_X_test)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.07623909413814545\n",
      "10 0.05530227720737457\n",
      "20 0.050052884966135025\n",
      "30 0.04673120379447937\n",
      "40 0.04454762861132622\n",
      "50 0.04316195845603943\n",
      "60 0.04214479401707649\n",
      "70 0.0413069948554039\n",
      "80 0.040652792900800705\n",
      "90 0.04015569016337395\n",
      "100 0.039709609001874924\n",
      "110 0.0393243208527565\n",
      "120 0.03899726644158363\n",
      "130 0.038728248327970505\n",
      "140 0.038529690355062485\n",
      "150 0.038393884897232056\n",
      "160 0.038286466151475906\n",
      "170 0.038236457854509354\n",
      "180 0.038228489458560944\n",
      "190 0.038278672844171524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=3091, out_features=250, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=250, out_features=250, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=250, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelFit()\n",
    "model.fit(ens_X_train, y_train, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(ens_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Loaded_Language', 'Loaded_Language', 'Name_Calling,Labeling', ...,\n",
       "       'Loaded_Language', 'Name_Calling,Labeling', 'Flag-Waving'],\n",
       "      dtype='<U30')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_label(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions written to file ../predictions/ablation_wo_finetuning.txt\n"
     ]
    }
   ],
   "source": [
    "test_df[\"gold_label\"] = model.get_label(y_pred)\n",
    "datawriter = DataWriter()\n",
    "datawriter.pred_writer(test_df, \"../predictions/ablation_wo_finetuning.txt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
